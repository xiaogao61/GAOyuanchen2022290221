import pandas as pd
from model_ollama import query_model
from tqdm import tqdm

# âœ… ä¿®å¤åçš„é¢„æµ‹è§£æå‡½æ•°
def parse_prediction(result):
    """
    æ”¹è¿›ï¼šä»å¤šå¥è¾“å‡ºä¸­ä»…å–æœ€åä¸€å¥åˆ¤æ–­çœŸ/å‡ã€‚
    """
    if not result or not isinstance(result, str):
        return -1

    # æ¸…æ´—æ ‡ç­¾
    tags_to_remove = ["<|assistant|>", "<|think|>", "</think>"]
    for tag in tags_to_remove:
        result = result.replace(tag, "")

    # æ‹†å¥ï¼šåªå–æœ€åä¸€å¥åšåˆ¤æ–­
    lines = [line.strip() for line in result.strip().splitlines() if line.strip()]
    final_line = lines[-1] if lines else ""

    final_line = final_line.replace("ï¼š", "").replace("ã€‚", "").replace(".", "").strip().lower()

    if final_line in ["å‡", "è™šå‡", "æ˜¯å‡çš„", "ä¸ºå‡", "æ–°é—»æ˜¯å‡"]:
        return 1  # å‡æ–°é—»
    elif final_line in ["çœŸ", "çœŸå®", "æ˜¯çœŸçš„", "ä¸ºçœŸ", "æ–°é—»æ˜¯çœŸ"]:
        return 0  # çœŸæ–°é—»
    elif "å‡" in final_line and "çœŸ" not in final_line:
        return 1
    elif "çœŸ" in final_line and "å‡" not in final_line:
        return 0
    else:
        return -1


# âœ… ä»»åŠ¡1ï¼šç›´æ¥åˆ¤æ–­çœŸå‡
def classify(news_rows):
    preds = []
    for idx, row in tqdm(news_rows.iterrows(), total=len(news_rows), desc="ä»»åŠ¡1 - åˆ¤æ–­çœŸå‡"):
        prompt = f"""è¯·åˆ¤æ–­ä»¥ä¸‹æ–°é—»æ˜¯çœŸæ–°é—»è¿˜æ˜¯å‡æ–°é—»ï¼Ÿåªå›ç­”â€œçœŸâ€æˆ–â€œå‡â€ã€‚

æ–°é—»å†…å®¹ï¼š{row['content']}"""
        result = query_model(prompt)
        pred = parse_prediction(result)

        print(f"\nğŸ“° ç¬¬{idx+1}æ¡æ–°é—»ï¼š{row['content']}")
        print(f"ğŸ¤– åŸå§‹è¾“å‡ºï¼š{result}")
        print(f"âœ… çœŸå®æ ‡ç­¾ï¼š{'å‡' if row['label'] == 1 else 'çœŸ'}")
        print(f"ğŸ” æ¨¡å‹åˆ¤æ–­ï¼š{'å‡' if pred == 1 else 'çœŸ' if pred == 0 else 'æ— æ³•åˆ¤æ–­'}")

        preds.append(pred)
    return preds

# âœ… ä»»åŠ¡2ï¼šæƒ…æ„Ÿåˆ†æ
def analyze_sentiment(news_rows):
    few_shot_prompt = """è¯·åˆ¤æ–­ä¸‹é¢æ–°é—»çš„æƒ…æ„Ÿå€¾å‘ï¼Œåªå›ç­”â€œç§¯æâ€ã€â€œæ¶ˆæâ€æˆ–â€œä¸­æ€§â€ï¼Œä¸è¦å¤šä½™æ–‡å­—ã€‚

ç¤ºä¾‹ï¼š
æ–°é—»å†…å®¹ï¼šå…¬å¸ä¸šç»©å¤§å¹…å¢é•¿ï¼Œå¸‚åœºåå“çƒ­çƒˆã€‚
å›ç­”ï¼šç§¯æ

æ–°é—»å†…å®¹ï¼šè¿‘æœŸå¤©æ°”æ¶åŠ£ï¼Œå¯¼è‡´äº¤é€šä¸¥é‡å µå¡ã€‚
å›ç­”ï¼šæ¶ˆæ

æ–°é—»å†…å®¹ï¼šä¼šè®®å¦‚æœŸä¸¾è¡Œï¼Œå†…å®¹æ­£å¸¸ã€‚
å›ç­”ï¼šä¸­æ€§

ç°åœ¨åˆ¤æ–­ä»¥ä¸‹æ–°é—»ï¼š
æ–°é—»å†…å®¹ï¼š
"""
    sentiments = []
    for idx, row in tqdm(news_rows.iterrows(), total=len(news_rows), desc="ä»»åŠ¡2 - åˆ†ææƒ…æ„Ÿ"):
        prompt = few_shot_prompt + row['content'] + "\nå›ç­”ï¼š"
        result = query_model(prompt)

        # æå–æœ€åä¸€è¡Œä½œä¸ºåˆ¤æ–­ä¾æ®
        lines = [line.strip() for line in result.strip().splitlines() if line.strip()]
        final_line = lines[-1] if lines else ""
        final_line = final_line.replace("ã€‚", "").replace("ï¼š", "").strip()

        print(f"\nğŸ“° ç¬¬{idx+1}æ¡æ–°é—»ï¼š{row['content']}")
        print(f"ğŸ¤– æ¨¡å‹è¾“å‡ºå®Œæ•´å†…å®¹ï¼š{result}")
        print(f"ğŸ” æœ€åä¸€è¡Œåˆ¤æ–­å€¼ï¼š{final_line}")

        if final_line == "ç§¯æ":
            sentiments.append("ç§¯æ")
        elif final_line == "æ¶ˆæ":
            sentiments.append("æ¶ˆæ")
        elif final_line == "ä¸­æ€§":
            sentiments.append("ä¸­æ€§")
        else:
            sentiments.append("ä¸­æ€§")
            print("âš ï¸ æœªèƒ½å‡†ç¡®è¯†åˆ«æƒ…æ„Ÿï¼Œé»˜è®¤æ ‡è®°ä¸ºä¸­æ€§")
    return sentiments


# âœ… ä»»åŠ¡3ï¼šç»“åˆæƒ…æ„Ÿåˆ¤æ–­çœŸå‡
def classify_with_sentiment(news_rows, sentiments):
    preds = []
    for idx, ((_, row), sent) in enumerate(zip(news_rows.iterrows(), sentiments)):
        prompt = f"""è¿™æ¡æ–°é—»çš„æƒ…æ„Ÿæ˜¯â€œ{sent}â€ï¼ˆä¾›å‚è€ƒï¼‰ã€‚è¯·ä½ æ ¹æ®æ–°é—»å†…å®¹æ¥åˆ¤æ–­è¯¥æ–°é—»æ˜¯çœŸæ–°é—»è¿˜æ˜¯å‡æ–°é—»ï¼Ÿåªå›ç­”â€œçœŸâ€æˆ–â€œå‡â€ã€‚

æ–°é—»å†…å®¹ï¼š{row['content']}"""
        result = query_model(prompt)
        pred = parse_prediction(result)

        print(f"\nğŸ“° ç¬¬{idx+1}æ¡æ–°é—»ï¼š{row['content']}")
        print(f"ğŸ’¬ æƒ…æ„Ÿå‚è€ƒï¼š{sent}")
        print(f"ğŸ¤– æ¨¡å‹è¾“å‡ºï¼š{result}")
        print(f"âœ… çœŸå®æ ‡ç­¾ï¼š{'å‡' if row['label'] == 1 else 'çœŸ'}")
        print(f"ğŸ” æ¨¡å‹åˆ¤æ–­ï¼š{'å‡' if pred == 1 else 'çœŸ' if pred == 0 else 'æ— æ³•åˆ¤æ–­'}")

        preds.append(pred)
    return preds

# âœ… å‡†ç¡®ç‡ç»Ÿè®¡å‡½æ•°ï¼ˆè·³è¿‡ -1 çš„ç»“æœï¼‰
def evaluate(preds, labels):
    clean_pairs = [(p, l) for p, l in zip(preds, labels) if p in [0, 1]]
    if not clean_pairs:
        return {"Accuracy": 0, "Accuracy_fake": 0, "Accuracy_true": 0}

    clean_preds, clean_labels = zip(*clean_pairs)
    correct = sum([p == l for p, l in clean_pairs])
    total = len(clean_pairs)

    correct_fake = sum([1 for p, l in clean_pairs if l == 1 and p == 1])
    total_fake = sum([1 for l in clean_labels if l == 1])

    correct_true = sum([1 for p, l in clean_pairs if l == 0 and p == 0])
    total_true = sum([1 for l in clean_labels if l == 0])

    return {
        "Accuracy": round(correct / total, 4),
        "Accuracy_fake": round(correct_fake / total_fake, 4) if total_fake else 0,
        "Accuracy_true": round(correct_true / total_true, 4) if total_true else 0
    }

# âœ… ä¸»ç¨‹åº
if __name__ == "__main__":
    print("ğŸ“„ åŠ è½½æµ‹è¯•é›†æ•°æ®å¹¶æŠ½æ ·10æ¡...")
    df_test = pd.read_csv("train.csv").sample(n=10, random_state=42).reset_index(drop=True)

    # ç¡®ä¿æ ‡ç­¾æ˜¯æ•´æ•°
    df_test['label'] = df_test['label'].astype(int)

    print("ğŸš€ ä»»åŠ¡1ï¼šç›´æ¥åˆ¤æ–­çœŸå‡æ–°é—»")
    preds1 = classify(df_test)
    eval1 = evaluate(preds1, df_test['label'].tolist())

    print("\nğŸ” ä»»åŠ¡2ï¼šæƒ…æ„Ÿåˆ†æ")
    sentiments = analyze_sentiment(df_test)

    print("\nğŸ” ä»»åŠ¡3ï¼šç»“åˆæƒ…æ„Ÿåˆ¤æ–­çœŸå‡æ–°é—»")
    preds3 = classify_with_sentiment(df_test, sentiments)
    eval3 = evaluate(preds3, df_test['label'].tolist())

    print("\nâœ… å‡†ç¡®ç‡æ±‡æ€»ï¼š")
    print("ä»»åŠ¡1ï¼ˆç›´æ¥åˆ¤æ–­ï¼‰ï¼š", eval1)
    print("ä»»åŠ¡3ï¼ˆç»“åˆæƒ…æ„Ÿï¼‰ï¼š", eval3)

    print("\nğŸ“ˆ æå‡åˆ†æï¼š")
    print("Accuracy æå‡ï¼š", round(eval3['Accuracy'] - eval1['Accuracy'], 4))
    print("Accuracy_fake æå‡ï¼š", round(eval3['Accuracy_fake'] - eval1['Accuracy_fake'], 4))
    print("Accuracy_true æå‡ï¼š", round(eval3['Accuracy_true'] - eval1['Accuracy_true'], 4))
